{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appliying Machine learning in Carnatic Music Classification with less attributed values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('music.xlsx')\n",
    "df_train = df.drop(['UID','MBID of the recording','Name','Artist','Release+Volume','Lead Instrument Code','Raaga','Excerpt Start Time (s)','Excerpt End Time (s)'], axis = 1)\n",
    "X = df_train .drop('Taala',axis=1).values\n",
    "y = df_train ['Taala'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Taala</th>\n",
       "      <th>Length of the excerpt (s)</th>\n",
       "      <th>Length of the excerpt (min)</th>\n",
       "      <th>Number of annotated beats</th>\n",
       "      <th>Number of samas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>2.48</td>\n",
       "      <td>193</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>3.95</td>\n",
       "      <td>368</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>5.87</td>\n",
       "      <td>481</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>8.50</td>\n",
       "      <td>825</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>514</td>\n",
       "      <td>8.57</td>\n",
       "      <td>705</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>4.25</td>\n",
       "      <td>397</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3</td>\n",
       "      <td>415</td>\n",
       "      <td>6.92</td>\n",
       "      <td>703</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>2.15</td>\n",
       "      <td>223</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>4.42</td>\n",
       "      <td>487</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>3.30</td>\n",
       "      <td>325</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Taala  Length of the excerpt (s)  Length of the excerpt (min)  \\\n",
       "0        0                        149                         2.48   \n",
       "1        0                        237                         3.95   \n",
       "2        0                        352                         5.87   \n",
       "3        0                        510                         8.50   \n",
       "4        0                        514                         8.57   \n",
       "..     ...                        ...                          ...   \n",
       "171      3                        255                         4.25   \n",
       "172      3                        415                         6.92   \n",
       "173      3                        129                         2.15   \n",
       "174      3                        265                         4.42   \n",
       "175      3                        198                         3.30   \n",
       "\n",
       "     Number of annotated beats  Number of samas  \n",
       "0                          193               25  \n",
       "1                          368               46  \n",
       "2                          481               61  \n",
       "3                          825              104  \n",
       "4                          705               89  \n",
       "..                         ...              ...  \n",
       "171                        397              133  \n",
       "172                        703              235  \n",
       "173                        223               75  \n",
       "174                        487              163  \n",
       "175                        325              109  \n",
       "\n",
       "[176 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 149.  ,    2.48,  193.  ,   25.  ],\n",
       "       [ 237.  ,    3.95,  368.  ,   46.  ],\n",
       "       [ 352.  ,    5.87,  481.  ,   61.  ],\n",
       "       [ 510.  ,    8.5 ,  825.  ,  104.  ],\n",
       "       [ 514.  ,    8.57,  705.  ,   89.  ],\n",
       "       [ 216.  ,    3.6 ,  305.  ,   39.  ],\n",
       "       [ 423.  ,    7.05,  681.  ,   86.  ],\n",
       "       [ 295.  ,    4.92,  520.  ,   65.  ],\n",
       "       [ 173.  ,    2.88,  241.  ,   31.  ],\n",
       "       [ 534.  ,    8.9 ,  881.  ,  111.  ],\n",
       "       [ 507.  ,    8.45,  793.  ,  100.  ],\n",
       "       [ 402.  ,    6.7 ,  496.  ,   62.  ],\n",
       "       [ 120.  ,    2.  ,  194.  ,   25.  ],\n",
       "       [ 183.  ,    3.05,  440.  ,   55.  ],\n",
       "       [ 212.  ,    3.53,  275.  ,   35.  ],\n",
       "       [ 309.  ,    5.15,  465.  ,   59.  ],\n",
       "       [ 234.  ,    3.9 ,  305.  ,   39.  ],\n",
       "       [ 260.  ,    4.33,  441.  ,   56.  ],\n",
       "       [ 748.  ,   12.47, 1266.  ,  159.  ],\n",
       "       [ 268.  ,    4.47,  376.  ,   47.  ],\n",
       "       [ 215.  ,    3.58,  321.  ,   41.  ],\n",
       "       [ 161.  ,    2.68,  209.  ,   27.  ],\n",
       "       [ 331.  ,    5.52,  409.  ,   52.  ],\n",
       "       [ 174.  ,    2.9 ,  283.  ,   36.  ],\n",
       "       [ 221.  ,    3.68,  313.  ,   40.  ],\n",
       "       [ 120.  ,    2.  ,  201.  ,   26.  ],\n",
       "       [  97.  ,    1.62,  158.  ,   20.  ],\n",
       "       [ 371.  ,    6.18,  529.  ,   67.  ],\n",
       "       [ 327.  ,    5.45,  480.  ,   60.  ],\n",
       "       [ 213.  ,    3.55,  289.  ,   37.  ],\n",
       "       [ 498.  ,    8.3 ,  657.  ,   83.  ],\n",
       "       [ 299.  ,    4.98,  439.  ,   55.  ],\n",
       "       [ 239.  ,    3.98,  345.  ,   44.  ],\n",
       "       [ 365.  ,    6.08,  537.  ,   68.  ],\n",
       "       [ 287.  ,    4.78,  449.  ,   57.  ],\n",
       "       [ 406.  ,    6.77,  618.  ,   78.  ],\n",
       "       [ 141.  ,    2.35,  185.  ,   24.  ],\n",
       "       [ 282.  ,    4.7 ,  480.  ,   60.  ],\n",
       "       [ 357.  ,    5.95,  505.  ,   64.  ],\n",
       "       [ 325.  ,    5.42,  433.  ,   55.  ],\n",
       "       [ 469.  ,    7.82,  665.  ,   84.  ],\n",
       "       [ 144.  ,    2.4 ,  192.  ,   24.  ],\n",
       "       [ 109.  ,    1.82,  223.  ,   28.  ],\n",
       "       [ 527.  ,    8.78,  761.  ,   96.  ],\n",
       "       [ 311.  ,    5.18,  417.  ,   53.  ],\n",
       "       [ 536.  ,    8.93,  777.  ,   98.  ],\n",
       "       [  86.  ,    1.43,  168.  ,   21.  ],\n",
       "       [ 394.  ,    6.57,  529.  ,   67.  ],\n",
       "       [ 357.  ,    5.95,  545.  ,   69.  ],\n",
       "       [ 159.  ,    2.65,  425.  ,   54.  ],\n",
       "       [ 457.  ,    7.62,  586.  ,  196.  ],\n",
       "       [ 180.  ,    3.  ,  223.  ,   75.  ],\n",
       "       [ 291.  ,    4.85,  427.  ,  143.  ],\n",
       "       [ 231.  ,    3.85,  462.  ,  154.  ],\n",
       "       [ 490.  ,    8.17,  655.  ,  219.  ],\n",
       "       [ 361.  ,    6.02,  505.  ,  169.  ],\n",
       "       [ 252.  ,    4.2 ,  385.  ,  129.  ],\n",
       "       [ 253.  ,    4.22,  310.  ,  104.  ],\n",
       "       [ 283.  ,    4.72,  340.  ,  114.  ],\n",
       "       [ 222.  ,    3.7 ,  310.  ,  104.  ],\n",
       "       [ 236.  ,    3.93,  313.  ,  105.  ],\n",
       "       [ 199.  ,    3.32,  340.  ,  114.  ],\n",
       "       [ 288.  ,    4.8 ,  453.  ,  151.  ],\n",
       "       [ 144.  ,    2.4 ,  232.  ,   78.  ],\n",
       "       [ 394.  ,    6.57,  586.  ,  196.  ],\n",
       "       [ 198.  ,    3.3 ,  301.  ,  101.  ],\n",
       "       [ 255.  ,    4.25,  526.  ,  176.  ],\n",
       "       [ 187.  ,    3.12,  250.  ,   84.  ],\n",
       "       [ 174.  ,    2.9 ,  232.  ,   78.  ],\n",
       "       [ 542.  ,    9.03,  865.  ,  289.  ],\n",
       "       [ 895.  ,   14.92, 1346.  ,  449.  ],\n",
       "       [ 932.  ,   15.53, 1247.  ,  416.  ],\n",
       "       [ 312.  ,    5.2 ,  412.  ,  138.  ],\n",
       "       [ 974.  ,   16.23, 1158.  ,  386.  ],\n",
       "       [ 200.  ,    3.33,  256.  ,   86.  ],\n",
       "       [ 191.  ,    3.18,  241.  ,   81.  ],\n",
       "       [ 362.  ,    6.03,  499.  ,  167.  ],\n",
       "       [ 458.  ,    7.63,  624.  ,  208.  ],\n",
       "       [ 292.  ,    4.87,  406.  ,  136.  ],\n",
       "       [ 444.  ,    7.4 ,  602.  ,  201.  ],\n",
       "       [ 453.  ,    7.55,  611.  ,  204.  ],\n",
       "       [ 247.  ,    4.12,  298.  ,  100.  ],\n",
       "       [ 252.  ,    4.2 ,  357.  ,  119.  ],\n",
       "       [ 187.  ,    3.12,  250.  ,   84.  ],\n",
       "       [ 189.  ,    3.15,  277.  ,   93.  ],\n",
       "       [ 318.  ,    5.3 ,  511.  ,  171.  ],\n",
       "       [ 184.  ,    3.07,  236.  ,   79.  ],\n",
       "       [ 327.  ,    5.45,  444.  ,  148.  ],\n",
       "       [ 274.  ,    4.57,  355.  ,  119.  ],\n",
       "       [ 268.  ,    4.47,  412.  ,  138.  ],\n",
       "       [ 285.  ,    4.75,  385.  ,  129.  ],\n",
       "       [ 322.  ,    5.37,  421.  ,  141.  ],\n",
       "       [ 184.  ,    3.07,  226.  ,   76.  ],\n",
       "       [ 198.  ,    3.3 ,  243.  ,   81.  ],\n",
       "       [ 137.  ,    2.28,  223.  ,   75.  ],\n",
       "       [ 337.  ,    5.62,  502.  ,  168.  ],\n",
       "       [ 343.  ,    5.72,  484.  ,  162.  ],\n",
       "       [ 281.  ,    4.68,  480.  ,  160.  ],\n",
       "       [ 440.  ,    7.33,  683.  ,  228.  ],\n",
       "       [ 124.  ,    2.07,  178.  ,   60.  ],\n",
       "       [ 236.  ,    3.93,  349.  ,   88.  ],\n",
       "       [ 603.  ,   10.05,  949.  ,  238.  ],\n",
       "       [ 546.  ,    9.1 ,  801.  ,  201.  ],\n",
       "       [ 309.  ,    5.15,  397.  ,  100.  ],\n",
       "       [ 356.  ,    5.93,  758.  ,  189.  ],\n",
       "       [ 389.  ,    6.48,  485.  ,  122.  ],\n",
       "       [ 274.  ,    4.57,  329.  ,   83.  ],\n",
       "       [ 506.  ,    8.43,  689.  ,  173.  ],\n",
       "       [ 374.  ,    6.23,  609.  ,  153.  ],\n",
       "       [ 499.  ,    8.32,  841.  ,  211.  ],\n",
       "       [ 606.  ,   10.1 ,  981.  ,  246.  ],\n",
       "       [ 385.  ,    6.42,  553.  ,  139.  ],\n",
       "       [ 485.  ,    8.08,  829.  ,  208.  ],\n",
       "       [ 543.  ,    9.05,  972.  ,  243.  ],\n",
       "       [ 267.  ,    4.45,  445.  ,  112.  ],\n",
       "       [ 237.  ,    3.95,  368.  ,   92.  ],\n",
       "       [ 237.  ,    3.95,  329.  ,   83.  ],\n",
       "       [ 489.  ,    8.15,  726.  ,  182.  ],\n",
       "       [ 320.  ,    5.33,  409.  ,  103.  ],\n",
       "       [ 325.  ,    5.42,  609.  ,  153.  ],\n",
       "       [ 444.  ,    7.4 ,  799.  ,  200.  ],\n",
       "       [ 231.  ,    3.85,  377.  ,   95.  ],\n",
       "       [ 848.  ,   14.13, 1325.  ,  332.  ],\n",
       "       [ 305.  ,    5.08,  505.  ,  127.  ],\n",
       "       [ 115.  ,    1.92,  241.  ,   61.  ],\n",
       "       [ 269.  ,    4.48,  385.  ,   97.  ],\n",
       "       [ 380.  ,    6.33,  549.  ,  138.  ],\n",
       "       [ 549.  ,    9.15,  825.  ,  207.  ],\n",
       "       [ 399.  ,    6.65,  621.  ,  156.  ],\n",
       "       [ 392.  ,    6.53,  741.  ,  186.  ],\n",
       "       [ 270.  ,    4.5 ,  525.  ,  132.  ],\n",
       "       [ 389.  ,    6.48,  501.  ,  126.  ],\n",
       "       [ 238.  ,    3.97,  365.  ,   92.  ],\n",
       "       [ 650.  ,   10.83,  969.  ,  243.  ],\n",
       "       [ 424.  ,    7.07,  633.  ,  159.  ],\n",
       "       [ 445.  ,    7.42,  580.  ,  145.  ],\n",
       "       [ 579.  ,    9.65,  805.  ,  202.  ],\n",
       "       [ 557.  ,    9.28,  713.  ,  179.  ],\n",
       "       [ 621.  ,   10.35,  825.  ,  207.  ],\n",
       "       [ 695.  ,   11.58,  989.  ,  248.  ],\n",
       "       [ 861.  ,   14.35, 1225.  ,  307.  ],\n",
       "       [ 479.  ,    7.98,  697.  ,  175.  ],\n",
       "       [ 459.  ,    7.65,  557.  ,  140.  ],\n",
       "       [ 120.  ,    2.  ,  159.  ,   40.  ],\n",
       "       [ 430.  ,    7.17,  641.  ,  161.  ],\n",
       "       [ 345.  ,    5.75,  417.  ,  105.  ],\n",
       "       [ 287.  ,    4.78,  449.  ,  113.  ],\n",
       "       [ 761.  ,   12.68, 1209.  ,  303.  ],\n",
       "       [ 484.  ,    8.07,  544.  ,  182.  ],\n",
       "       [ 401.  ,    6.68,  595.  ,  199.  ],\n",
       "       [ 205.  ,    3.42,  349.  ,  117.  ],\n",
       "       [ 501.  ,    8.35,  820.  ,  274.  ],\n",
       "       [ 426.  ,    7.1 ,  712.  ,  238.  ],\n",
       "       [ 116.  ,    1.93,  190.  ,   64.  ],\n",
       "       [ 302.  ,    5.03,  502.  ,  168.  ],\n",
       "       [ 181.  ,    3.02,  376.  ,  126.  ],\n",
       "       [ 286.  ,    4.77,  468.  ,  156.  ],\n",
       "       [ 222.  ,    3.7 ,  439.  ,  147.  ],\n",
       "       [ 533.  ,    8.88,  889.  ,  297.  ],\n",
       "       [ 342.  ,    5.7 ,  643.  ,  215.  ],\n",
       "       [ 495.  ,    8.25,  739.  ,  247.  ],\n",
       "       [ 331.  ,    5.52,  598.  ,  200.  ],\n",
       "       [ 224.  ,    3.73,  328.  ,  110.  ],\n",
       "       [ 312.  ,    5.2 ,  490.  ,  164.  ],\n",
       "       [ 164.  ,    2.73,  247.  ,   83.  ],\n",
       "       [ 128.  ,    2.13,  361.  ,  121.  ],\n",
       "       [ 244.  ,    4.07,  324.  ,  108.  ],\n",
       "       [ 199.  ,    3.32,  298.  ,  100.  ],\n",
       "       [ 164.  ,    2.73,  232.  ,   78.  ],\n",
       "       [ 291.  ,    4.85,  432.  ,  144.  ],\n",
       "       [ 264.  ,    4.4 ,  400.  ,  134.  ],\n",
       "       [ 255.  ,    4.25,  397.  ,  133.  ],\n",
       "       [ 415.  ,    6.92,  703.  ,  235.  ],\n",
       "       [ 129.  ,    2.15,  223.  ,   75.  ],\n",
       "       [ 265.  ,    4.42,  487.  ,  163.  ],\n",
       "       [ 198.  ,    3.3 ,  325.  ,  109.  ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Univariate Selection\n",
    "\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "\t# configure to select all features\n",
    "\tfs = SelectKBest(score_func=f_classif, k='all')\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_train, y_train)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\t# transform test input data\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 4.857845\n",
      "Feature 1: 4.856098\n",
      "Feature 2: 4.891852\n",
      "Feature 3: 19.320271\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "#pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learing algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 3]\n",
      " [3 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [2 3]\n",
      " [3 2]\n",
      " [3 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [3 1]\n",
      " [2 3]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [2 0]\n",
      " [3 1]\n",
      " [1 1]\n",
      " [3 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [1 3]\n",
      " [2 2]\n",
      " [1 3]\n",
      " [0 0]\n",
      " [3 1]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 1]\n",
      " [1 3]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 3]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  1  0]\n",
      " [ 0  8  0  7]\n",
      " [ 0  1 14  1]\n",
      " [ 0  5  2  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6792452830188679"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Logistic Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 3]\n",
      " [3 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [3 3]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [3 1]\n",
      " [1 3]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [3 1]\n",
      " [1 1]\n",
      " [3 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [2 2]\n",
      " [1 3]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [3 3]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0  0]\n",
      " [ 0 11  0  4]\n",
      " [ 0  0 16  0]\n",
      " [ 0  3  0  4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8679245283018868"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 3]\n",
      " [3 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [1 3]\n",
      " [2 2]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [3 1]\n",
      " [2 3]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [2 0]\n",
      " [3 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 2]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [0 3]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 1]\n",
      " [2 3]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [0 0]\n",
      " [2 2]\n",
      " [3 1]\n",
      " [2 2]\n",
      " [0 0]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  1  0]\n",
      " [ 0 10  0  5]\n",
      " [ 1  1 14  0]\n",
      " [ 1  2  3  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7358490566037735"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we used 4 features and one label for classification of carnatic music ,and apply the feature selection for finding highly correlated attribute and then apply 4 machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Random Forest Classifier--- 70.45%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)Logistic Regression Classifier= 82%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)Decision Tree Classifier=80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here we conclude that the best ml algorithm for carnatic music classification is LR and Decision Tree after reducing the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
